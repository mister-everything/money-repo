/**
 * AI Provider Prices Seed Data
 *
 * ì‹¤ì œ AI ì œê³µìë“¤ì˜ ê°€ê²© ì •ë³´ (2025ë…„ 12ì›” ê¸°ì¤€)
 * ì¶œì²˜: ê° AI ì œê³µìì˜ ê³µì‹ ê°€ê²© í˜ì´ì§€
 */

import { pgDb } from "../db";
import { logger } from "../logger";
import { AiProviderPricesTable } from "./schema";

/**
 * Payment ëª¨ë“ˆ ì‹œë“œ ë°ì´í„° ìƒì„±
 * AI ì œê³µì ê°€ê²© ì •ë³´ ìƒì„±
 */
export const seedPrices = async () => {
  logger.info("ğŸŒ± Seeding AI Provider Prices...");

  const prices: (typeof AiProviderPricesTable.$inferInsert)[] = [
    {
      provider: "xai",
      model: "grok-4.1-fast-non-reasoning",
      displayName: "Grok 4.1",
      modelType: "text",
      inputTokenPrice: "0.00000020",
      outputTokenPrice: "0.00000050",
      cachedTokenPrice: "0.00000005",
      markupRate: "1.600",
      isActive: true,
      isDefaultModel: false,
    },
    {
      provider: "google",
      model: "gemini-3-flash",
      displayName: "Gemini 3",
      modelType: "text",
      inputTokenPrice: "0.00000050",
      outputTokenPrice: "0.00000300",
      cachedTokenPrice: "0.00000005",
      markupRate: "1.600",
      isActive: true,
      isDefaultModel: true,
    },
    {
      provider: "anthropic",
      model: "claude-haiku-4.5",
      displayName: "Claude Haiku 4.5",
      modelType: "text",
      inputTokenPrice: "0.00000100",
      outputTokenPrice: "0.00000500",
      cachedTokenPrice: "0.00000010",
      markupRate: "1.600",
      isActive: true,
      isDefaultModel: false,
    },
    {
      provider: "openai",
      model: "gpt-5.1-instant",
      displayName: "GPT-5.1",
      modelType: "text",
      inputTokenPrice: "0.00000125",
      outputTokenPrice: "0.00001000",
      cachedTokenPrice: "0.00000013",
      markupRate: "1.600",
      isActive: true,
      isDefaultModel: false,
    },
    {
      provider: "openai",
      model: "gpt-5.1-thinking",
      displayName: "GPT 5.1 Thinking",
      modelType: "text",
      inputTokenPrice: "0.00000125",
      outputTokenPrice: "0.00001000",
      cachedTokenPrice: "0.00000013",
      markupRate: "1.600",
      isActive: true,
      isDefaultModel: false,
    },
    {
      provider: "google",
      model: "gemini-3-pro-preview",
      displayName: "Gemini 3 Pro",
      modelType: "text",
      inputTokenPrice: "0.00000200",
      outputTokenPrice: "0.00001200",
      cachedTokenPrice: "0.00000020",
      markupRate: "1.600",
      isActive: true,
      isDefaultModel: false,
    },
    {
      provider: "openai",
      model: "gpt-5.2-chat",
      displayName: "GPT-5.2",
      modelType: "text",
      inputTokenPrice: "0.00000175",
      outputTokenPrice: "0.00001400",
      cachedTokenPrice: "0.00000018",
      markupRate: "1.600",
      isActive: true,
      isDefaultModel: false,
    },
  ];

  const inserted = await pgDb
    .insert(AiProviderPricesTable)
    .values(prices)
    .onConflictDoNothing()
    .returning();

  logger.info(`âœ… Seeded ${inserted.length} AI provider prices`);

  // Print summary
  if (inserted.length > 0) {
    logger.info("\nğŸ“Š Price Summary:");
    for (const price of inserted) {
      logger.info(
        `  ${price.displayName} (${price.provider}/${price.model}): $${price.inputTokenPrice}/token in, $${price.outputTokenPrice}/token out (${Number(price.markupRate) * 100 - 100}% markup)`,
      );
    }
  }

  logger.info("âœ… Payment ì‹œë“œ ë°ì´í„° ìƒì„± ì™„ë£Œ\n");
};

// Run if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
  import("@workspace/env");
  seedPrices()
    .then(() => {
      logger.info("\nâœ… Seed completed!");
      process.exit(0);
    })
    .catch((error) => {
      logger.error("âŒ Seed failed:", error);
      process.exit(1);
    });
}
